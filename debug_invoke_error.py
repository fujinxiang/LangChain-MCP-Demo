#!/usr/bin/env python3
"""
è°ƒè¯• LLM invoke é”™è¯¯
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_llm_invoke():
    """æµ‹è¯• LLM invoke æ–¹æ³•"""
    print("ğŸ”§ æµ‹è¯• LLM invoke æ–¹æ³•...")
    
    try:
        from utils.llm_wrapper import SiliconFlowLLM
        
        # åˆ›å»º LLM å®ä¾‹
        llm = SiliconFlowLLM()
        print(f"âœ… LLM åˆ›å»ºæˆåŠŸï¼Œç±»å‹: {type(llm)}")
        print(f"âœ… LLM ç±»å‹æ ‡è¯†: {llm._llm_type}")
        
        # æ£€æŸ¥ invoke æ–¹æ³•
        print(f"âœ… æ˜¯å¦æœ‰ invoke æ–¹æ³•: {hasattr(llm, 'invoke')}")
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„è¾“å…¥
        test_prompt = "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤"
        
        print("\nğŸ“ æµ‹è¯•1: ç›´æ¥å­—ç¬¦ä¸²è°ƒç”¨")
        try:
            response = llm.invoke(test_prompt)
            print(f"âœ… å­—ç¬¦ä¸²è°ƒç”¨æˆåŠŸ: {response[:50]}...")
        except Exception as e:
            print(f"âŒ å­—ç¬¦ä¸²è°ƒç”¨å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e)}")
            import traceback
            traceback.print_exc()
        
        print("\nğŸ“ æµ‹è¯•2: å­—å…¸æ ¼å¼è°ƒç”¨")
        try:
            response = llm.invoke({"prompt": test_prompt})
            print(f"âœ… å­—å…¸è°ƒç”¨æˆåŠŸ: {response[:50]}...")
        except Exception as e:
            print(f"âŒ å­—å…¸è°ƒç”¨å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e)}")
        
        print("\nğŸ“ æµ‹è¯•3: åˆ—è¡¨æ ¼å¼è°ƒç”¨")
        try:
            from langchain.schema import HumanMessage
            messages = [HumanMessage(content=test_prompt)]
            response = llm.invoke(messages)
            print(f"âœ… æ¶ˆæ¯åˆ—è¡¨è°ƒç”¨æˆåŠŸ: {response[:50]}...")
        except Exception as e:
            print(f"âŒ æ¶ˆæ¯åˆ—è¡¨è°ƒç”¨å¤±è´¥: {e}")
            print(f"é”™è¯¯ç±»å‹: {type(e)}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def inspect_llm_structure():
    """æ£€æŸ¥ LLM ç±»çš„ç»“æ„"""
    print("\nğŸ” æ£€æŸ¥ LLM ç±»ç»“æ„...")
    
    try:
        from utils.llm_wrapper import SiliconFlowLLM
        from langchain.llms.base import LLM
        
        llm = SiliconFlowLLM()
        
        print(f"âœ… SiliconFlowLLM åŸºç±»: {SiliconFlowLLM.__bases__}")
        print(f"âœ… LLM åŸºç±»: {LLM.__bases__}")
        
        # æ£€æŸ¥å…³é”®æ–¹æ³•
        key_methods = ['invoke', '_call', '_stream', '_llm_type']
        for method in key_methods:
            has_method = hasattr(llm, method)
            print(f"âœ… {method}: {'å­˜åœ¨' if has_method else 'ä¸å­˜åœ¨'}")
            
        # æ£€æŸ¥ invoke æ–¹æ³•çš„æ¥æº
        if hasattr(llm, 'invoke'):
            print(f"âœ… invoke æ–¹æ³•æ¥æº: {llm.invoke.__qualname__}")
            
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸš€ LLM invoke é”™è¯¯è°ƒè¯•")
    print("=" * 50)
    
    inspect_llm_structure()
    test_llm_invoke()
