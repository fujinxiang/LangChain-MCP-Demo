"""
LangChain + ç¡…åŸºæµåŠ¨ Streamlit Web åº”ç”¨
æä¾›ç¾è§‚çš„ Web ç•Œé¢è¿›è¡ŒèŠå¤©å’Œæ–‡æ¡£é—®ç­”
"""

import streamlit as st
import sys
import os
from utils.llm_wrapper import create_llm
from utils.document_loader import DocumentLoader, SimpleVectorStore
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain


@st.cache_resource
def init_llm():
    """åˆå§‹åŒ– LLMï¼ˆç¼“å­˜ï¼‰"""
    try:
        return create_llm()
    except Exception as e:
        st.error(f"LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        st.stop()


@st.cache_resource
def init_qa_system():
    """åˆå§‹åŒ–æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼ˆç¼“å­˜ï¼‰"""
    llm = init_llm()
    doc_loader = DocumentLoader()
    vector_store = SimpleVectorStore()
    
    qa_prompt = PromptTemplate(
        input_variables=["context", "question"],
        template="""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜æ— æ³•ä»æä¾›çš„æ–‡æ¡£ä¸­æ‰¾åˆ°ç­”æ¡ˆã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

ç”¨æˆ·é—®é¢˜: {question}

å›ç­”:"""
    )
    
    qa_chain = LLMChain(llm=llm, prompt=qa_prompt)
    
    return {
        'llm': llm,
        'doc_loader': doc_loader,
        'vector_store': vector_store,
        'qa_chain': qa_chain
    }


def chat_page():
    """èŠå¤©é¡µé¢"""
    st.header("ğŸ’¬ AI èŠå¤©åŠ©æ‰‹")
    st.write("ä¸ AI åŠ©æ‰‹è¿›è¡Œå¯¹è¯ï¼Œä½“éªŒ LangChain + ç¡…åŸºæµåŠ¨çš„å¼ºå¤§åŠŸèƒ½ï¼")
    
    # åˆå§‹åŒ–èŠå¤©å†å²
    if "chat_messages" not in st.session_state:
        st.session_state.chat_messages = []
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.chat_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # èŠå¤©è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # è·å– AI å›å¤
        with st.chat_message("assistant"):
            with st.spinner("AI æ­£åœ¨æ€è€ƒ..."):
                try:
                    llm = init_llm()
                    
                    # åˆ›å»ºæç¤ºæ¨¡æ¿
                    prompt_template = PromptTemplate(
                        input_variables=["question"],
                        template="""ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

é—®é¢˜: {question}

å›ç­”:"""
                    )
                    
                    chain = LLMChain(llm=llm, prompt=prompt_template)
                    response = chain.run(question=prompt)
                    
                    st.markdown(response)
                    
                    # æ·»åŠ  AI å›å¤åˆ°å†å²
                    st.session_state.chat_messages.append({"role": "assistant", "content": response})
                    
                except Exception as e:
                    error_msg = f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯: {e}"
                    st.error(error_msg)
                    st.session_state.chat_messages.append({"role": "assistant", "content": error_msg})
    
    # æ¸…é™¤èŠå¤©å†å²æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…é™¤èŠå¤©å†å²"):
        st.session_state.chat_messages = []
        st.rerun()


def doc_qa_page():
    """æ–‡æ¡£é—®ç­”é¡µé¢"""
    st.header("ğŸ“„ æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
    st.write("ä¸Šä¼ æ–‡æ¡£æˆ–è¾“å…¥æ–‡æœ¬ï¼Œç„¶åå¯¹æ–‡æ¡£å†…å®¹è¿›è¡Œé—®ç­”ï¼")
    
    qa_system = init_qa_system()
    
    # åˆå§‹åŒ–æ–‡æ¡£å­˜å‚¨
    if "documents_loaded" not in st.session_state:
        st.session_state.documents_loaded = False
        st.session_state.doc_count = 0
    
    # æ–‡æ¡£è¾“å…¥åŒºåŸŸ
    st.subheader("ğŸ“ æ–‡æ¡£è¾“å…¥")
    
    input_method = st.radio(
        "é€‰æ‹©è¾“å…¥æ–¹å¼:",
        ["ç›´æ¥è¾“å…¥æ–‡æœ¬", "ä¸Šä¼ æ–‡æœ¬æ–‡ä»¶"],
        horizontal=True
    )
    
    documents_to_load = []
    
    if input_method == "ç›´æ¥è¾“å…¥æ–‡æœ¬":
        text_input = st.text_area(
            "è¯·è¾“å…¥æ‚¨çš„æ–‡æ¡£å†…å®¹:",
            height=200,
            placeholder="åœ¨è¿™é‡Œç²˜è´´æ‚¨çš„æ–‡æ¡£å†…å®¹..."
        )
        if text_input.strip():
            documents_to_load.append(("ç›´æ¥è¾“å…¥", text_input))
    
    else:
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡æœ¬æ–‡ä»¶",
            type=['txt'],
            accept_multiple_files=True
        )
        
        for uploaded_file in uploaded_files:
            content = uploaded_file.read().decode('utf-8')
            documents_to_load.append((uploaded_file.name, content))
    
    # åŠ è½½æ–‡æ¡£æŒ‰é’®
    if st.button("ğŸ“š åŠ è½½æ–‡æ¡£", disabled=len(documents_to_load) == 0):
        with st.spinner("æ­£åœ¨åŠ è½½æ–‡æ¡£..."):
            try:
                total_chunks = 0
                for source, content in documents_to_load:
                    documents = qa_system['doc_loader'].load_text_content(content, source)
                    qa_system['vector_store'].add_documents(documents)
                    total_chunks += len(documents)
                
                st.session_state.documents_loaded = True
                st.session_state.doc_count = total_chunks
                st.success(f"âœ… æˆåŠŸåŠ è½½ {total_chunks} ä¸ªæ–‡æ¡£ç‰‡æ®µï¼")
                
            except Exception as e:
                st.error(f"âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºæ–‡æ¡£çŠ¶æ€
    if st.session_state.documents_loaded:
        st.info(f"ğŸ“Š å½“å‰å·²åŠ è½½ {st.session_state.doc_count} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
    
    # é—®ç­”åŒºåŸŸ
    st.subheader("â“ æ–‡æ¡£é—®ç­”")
    
    if not st.session_state.documents_loaded:
        st.warning("è¯·å…ˆåŠ è½½æ–‡æ¡£åå†è¿›è¡Œé—®ç­”")
    else:
        # åˆå§‹åŒ–é—®ç­”å†å²
        if "qa_messages" not in st.session_state:
            st.session_state.qa_messages = []
        
        # æ˜¾ç¤ºé—®ç­”å†å²
        for message in st.session_state.qa_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # é—®ç­”è¾“å…¥
        if question := st.chat_input("è¯·é’ˆå¯¹æ–‡æ¡£å†…å®¹æé—®..."):
            # æ·»åŠ ç”¨æˆ·é—®é¢˜
            st.session_state.qa_messages.append({"role": "user", "content": question})
            with st.chat_message("user"):
                st.markdown(question)
            
            # è·å– AI å›ç­”
            with st.chat_message("assistant"):
                with st.spinner("AI æ­£åœ¨åˆ†ææ–‡æ¡£..."):
                    try:
                        # æœç´¢ç›¸å…³æ–‡æ¡£
                        relevant_docs = qa_system['vector_store'].similarity_search(question, k=3)
                        
                        if not relevant_docs:
                            answer = "æŠ±æ­‰ï¼Œæˆ‘åœ¨æä¾›çš„æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚"
                        else:
                            # æ„å»ºä¸Šä¸‹æ–‡
                            context = "\n\n".join([doc.page_content for doc in relevant_docs])
                            
                            # ç”Ÿæˆå›ç­”
                            answer = qa_system['qa_chain'].run(context=context, question=question)
                        
                        st.markdown(answer)
                        
                        # æ·»åŠ  AI å›ç­”åˆ°å†å²
                        st.session_state.qa_messages.append({"role": "assistant", "content": answer})
                        
                    except Exception as e:
                        error_msg = f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯: {e}"
                        st.error(error_msg)
                        st.session_state.qa_messages.append({"role": "assistant", "content": error_msg})
        
        # æ¸…é™¤é—®ç­”å†å²æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤é—®ç­”å†å²"):
            st.session_state.qa_messages = []
            st.rerun()


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="LangChain + ç¡…åŸºæµåŠ¨ Demo",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.title("ğŸ¤– LangChain + ç¡…åŸºæµåŠ¨")
        st.write("é€‰æ‹©åŠŸèƒ½æ¨¡å¼:")
        
        page = st.radio(
            "åŠŸèƒ½æ¨¡å¼",
            ["ğŸ’¬ AI èŠå¤©", "ğŸ“„ æ–‡æ¡£é—®ç­”"],
            label_visibility="collapsed"
        )
        
        st.markdown("---")
        st.subheader("â„¹ï¸ å…³äº")
        st.write("""
        è¿™æ˜¯ä¸€ä¸ªåŸºäº LangChain æ¡†æ¶å’Œç¡…åŸºæµåŠ¨ API æ„å»ºçš„æ¼”ç¤ºåº”ç”¨ã€‚
        
        **åŠŸèƒ½ç‰¹æ€§:**
        - AI æ™ºèƒ½å¯¹è¯
        - æ–‡æ¡£å†…å®¹é—®ç­”
        - æµç•…çš„ Web ç•Œé¢
        
        **æŠ€æœ¯æ ˆ:**
        - LangChain
        - ç¡…åŸºæµåŠ¨ API
        - Streamlit
        """)
        
        st.markdown("---")
        st.write("ğŸ’¡ **æç¤º**: ç¡®ä¿å·²æ­£ç¡®é…ç½® API Key")
    
    # ä¸»å†…å®¹åŒºåŸŸ
    if page == "ğŸ’¬ AI èŠå¤©":
        chat_page()
    elif page == "ğŸ“„ æ–‡æ¡£é—®ç­”":
        doc_qa_page()


if __name__ == "__main__":
    main()
